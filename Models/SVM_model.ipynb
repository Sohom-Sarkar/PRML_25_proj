{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWFPufNodjE6"
      },
      "source": [
        "# ðŸ§  SVM-Based VLSI Partitioning Model\n",
        "\n",
        "This notebook implements a Support Vector Machine (SVM)-based approach for partitioning VLSI netlists represented as graphs.\n",
        "\n",
        "### Model Logic:\n",
        "- Each node in the graph represents a circuit component with features:\n",
        "  - Power, Area, Average Edge Distance, Degree\n",
        "- Pseudo-labels for supervised learning are generated using **KMeans** clustering.\n",
        "- An **SVM classifier** is trained on the node features and labels.\n",
        "- After training, each node is assigned to a partition, and standard partitioning metrics are computed.\n",
        "\n",
        "### Goals:\n",
        "- Minimize inter-partition **cut edges**\n",
        "- Minimize total **wire length**\n",
        "- Balance **power and area** across partitions\n",
        "- Reduce **critical path delay**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yNK48HXtdkzz"
      },
      "outputs": [],
      "source": [
        "# SVM Partitioning Model\n",
        "# Uses pseudo-labels from KMeans and trains an SVM classifier on node features\n",
        "# Features used: [power, area, avg_edge_distance, degree]\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qWAb-9ufdmfB"
      },
      "outputs": [],
      "source": [
        "# Graph Gen 1.2\n",
        "# Added inputs and outputs\n",
        "# The power consumption for a node ranges from 1 to 50 units and uniformly distributed.\n",
        "# Plus the area may vary from 1 to 5 units as well, uniformly distributed\n",
        "# Ensured the following:\n",
        "# The input nodes must have at least one outgoing edge and no incoming edge\n",
        "# The output nodes must have one incoming edge only\n",
        "# Internal nodes must have at least one incoming and at least one outgoing edge\n",
        "\n",
        "def generate_netlist(\n",
        "    num_nodes=50,\n",
        "    num_edges=100,\n",
        "    enable_area=True,\n",
        "    enable_power=True,\n",
        "    enable_wire_count=True,\n",
        "    enable_distance=True,\n",
        "    seed=42\n",
        "):\n",
        "    G = nx.DiGraph()\n",
        "    num_inputs = math.ceil(math.log2(num_nodes))\n",
        "    num_outputs = math.ceil(num_inputs / 2)\n",
        "    input_nodes = [f\"IN_{i}\" for i in range(num_inputs)]\n",
        "    output_nodes = [f\"OUT_{i}\" for i in range(num_outputs)]\n",
        "    internal_nodes = [f\"N_{i}\" for i in range(num_nodes)]\n",
        "\n",
        "    for node in internal_nodes:\n",
        "        G.add_node(node)\n",
        "        if enable_area:\n",
        "            G.nodes[node]['area'] = round(random.uniform(1.0, 5.0), 2)\n",
        "        if enable_power:\n",
        "            G.nodes[node]['power'] = round(random.uniform(1.0, 50.0), 2)\n",
        "\n",
        "    for node in input_nodes + output_nodes:\n",
        "        G.add_node(node)\n",
        "\n",
        "    for input_node in input_nodes:\n",
        "        target = random.choice(internal_nodes)\n",
        "        G.add_edge(input_node, target)\n",
        "\n",
        "    for output_node in output_nodes:\n",
        "        source = random.choice(internal_nodes)\n",
        "        G.add_edge(source, output_node)\n",
        "\n",
        "    for node in internal_nodes:\n",
        "        if G.in_degree(node) == 0:\n",
        "            source = random.choice(input_nodes + internal_nodes)\n",
        "            G.add_edge(source, node)\n",
        "        if G.out_degree(node) == 0:\n",
        "            target = random.choice(internal_nodes + output_nodes)\n",
        "            G.add_edge(node, target)\n",
        "\n",
        "    existing_edges = set(G.edges())\n",
        "    while len(G.edges()) < num_edges:\n",
        "        u, v = random.sample(internal_nodes, 2)\n",
        "        if u != v and (u, v) not in existing_edges:\n",
        "            G.add_edge(u, v)\n",
        "            existing_edges.add((u, v))\n",
        "\n",
        "    for u, v in G.edges():\n",
        "        if enable_wire_count:\n",
        "            G.edges[u, v]['wires'] = random.randint(1, 5)\n",
        "        if enable_distance:\n",
        "            G.edges[u, v]['distance'] = round(random.uniform(1.0, 10.0), 2)\n",
        "\n",
        "    return G, input_nodes, output_nodes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "I0Flke-Fdn1g"
      },
      "outputs": [],
      "source": [
        "# Borrowed from KMeans_1d.ipynb\n",
        "# Computes number of inter-cluster cuts, wire length, and delay\n",
        "\n",
        "def compute_wire_metrics(G, cluster_labels, input_nodes, output_nodes):\n",
        "    num_cuts = 0\n",
        "    total_wire_length = 0\n",
        "    G_weighted = nx.DiGraph()\n",
        "\n",
        "    for u, v in G.edges():\n",
        "        wire_length = G.edges[u, v].get(\"distance\", 1)\n",
        "        cluster_u, cluster_v = cluster_labels.get(u), cluster_labels.get(v)\n",
        "\n",
        "        if cluster_u == cluster_v:\n",
        "            edge_weight = wire_length\n",
        "        else:\n",
        "            edge_weight = wire_length * 10\n",
        "            num_cuts += 1\n",
        "\n",
        "        total_wire_length += edge_weight\n",
        "        G_weighted.add_edge(u, v, weight=edge_weight)\n",
        "\n",
        "    while not nx.is_directed_acyclic_graph(G_weighted):\n",
        "        try:\n",
        "            cycle = next(nx.simple_cycles(G_weighted))\n",
        "            min_edge = min(\n",
        "                ((cycle[i], cycle[(i + 1) % len(cycle)]) for i in range(len(cycle))),\n",
        "                key=lambda e: G_weighted.edges[e].get(\"weight\", 1)\n",
        "            )\n",
        "            G_weighted.remove_edge(*min_edge)\n",
        "        except StopIteration:\n",
        "            break\n",
        "\n",
        "    critical_length = 0\n",
        "    for input_node in input_nodes:\n",
        "        if input_node in G_weighted.nodes:\n",
        "            for output_node in output_nodes:\n",
        "                if output_node in G_weighted.nodes:\n",
        "                    try:\n",
        "                        path = nx.dag_longest_path(G_weighted, weight=\"weight\")\n",
        "                        path_length = sum(G_weighted[u][v][\"weight\"] for u, v in zip(path, path[1:]))\n",
        "                        critical_length = max(critical_length, path_length)\n",
        "                    except nx.NetworkXNoPath:\n",
        "                        pass\n",
        "\n",
        "    return num_cuts, total_wire_length, critical_length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Tp8U6GYJdpnC"
      },
      "outputs": [],
      "source": [
        "# SVM Partition Model\n",
        "# Uses pseudo-labels from KMeans to train binary SVM classifier\n",
        "\n",
        "def extract_node_features(G):\n",
        "    features = []\n",
        "    node_ids = []\n",
        "    for node in G.nodes():\n",
        "        if node.startswith(\"IN_\") or node.startswith(\"OUT_\"):\n",
        "            continue\n",
        "\n",
        "        power = G.nodes[node].get(\"power\", 0)\n",
        "        area = G.nodes[node].get(\"area\", 0)\n",
        "        in_edges = G.in_edges(node)\n",
        "        out_edges = G.out_edges(node)\n",
        "        edge_distances = [G.edges[u, v].get(\"distance\", 1.0) for u, v in list(in_edges) + list(out_edges)]\n",
        "        avg_distance = np.mean(edge_distances) if edge_distances else 0.0\n",
        "        degree = G.in_degree(node) + G.out_degree(node)\n",
        "\n",
        "        features.append([power, area, avg_distance, degree])\n",
        "        node_ids.append(node)\n",
        "\n",
        "    return np.array(features), node_ids\n",
        "\n",
        "def svm_partition_model(G,k):\n",
        "    features, node_ids = extract_node_features(G)\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(features)\n",
        "\n",
        "    kmeans = KMeans(n_clusters=k, n_init=10)\n",
        "    y_pseudo = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "    clf = SVC(kernel='rbf', C=1.0, gamma='scale', decision_function_shape='ovo')  # ovo = one-vs-one (default)\n",
        "    clf.fit(X_scaled, y_pseudo)\n",
        "    y_pred = clf.predict(X_scaled)\n",
        "\n",
        "    return {node_ids[i]: int(y_pred[i]) for i in range(len(node_ids))}\n",
        "\n",
        "\n",
        "# This is the driver code that will implement multi class SVM and return the metrics\n",
        "def svm_model_driver(graph, inputs, outputs, k):\n",
        "\n",
        "  cluster_labels = svm_partition_model(graph,k)\n",
        "  num_cuts, total_wire_length, critical_length = compute_wire_metrics(graph, cluster_labels, inputs, outputs)\n",
        "  return num_cuts, critical_length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D6XK-NVmdsSa"
      },
      "outputs": [],
      "source": [
        "# Cluster Visualization\n",
        "\n",
        "def visualize_clusters(graph, cluster_labels):\n",
        "    pos = nx.spring_layout(graph, seed=42)\n",
        "    clusters = set(cluster_labels.values())\n",
        "    colors = plt.cm.tab20(np.linspace(0, 1, len(clusters)))\n",
        "\n",
        "    for i, cluster in enumerate(clusters):\n",
        "        nodes = [node for node in graph.nodes if cluster_labels.get(node, -1) == cluster]\n",
        "        nx.draw_networkx_nodes(graph, pos, nodelist=nodes, node_color=[colors[i]], label=f'Cluster {cluster}')\n",
        "\n",
        "    nx.draw_networkx_edges(graph, pos, alpha=0.4)\n",
        "    nx.draw_networkx_labels(graph, pos, font_size=8)\n",
        "    plt.title(\"SVM Partitioning of VLSI Netlist\")\n",
        "    plt.axis('off')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ccc7QSnBhWtT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running scaling analysis from 50 to 1000 nodes...\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'analyze_scaling' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m num_runs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning scaling analysis from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_nodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_nodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nodes...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m node_counts, avg_cuts, avg_wire_lengths, avg_critical_lengths \u001b[38;5;241m=\u001b[39m analyze_scaling(\n\u001b[0;32m     10\u001b[0m     min_nodes, max_nodes, step, num_runs\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalysis complete, generating plots...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m plot_scaling_results(node_counts, avg_cuts, avg_wire_lengths, avg_critical_lengths)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'analyze_scaling' is not defined"
          ]
        }
      ],
      "source": [
        "# Example run\n",
        "if __name__ == \"__main__\":\n",
        "    min_nodes = 50\n",
        "    max_nodes = 1000\n",
        "    step = 10\n",
        "    num_runs = 1\n",
        "    \n",
        "    print(f\"Running scaling analysis from {min_nodes} to {max_nodes} nodes...\")\n",
        "    node_counts, avg_cuts, avg_wire_lengths, avg_critical_lengths = analyze_scaling(\n",
        "        min_nodes, max_nodes, step, num_runs\n",
        "    )\n",
        "    \n",
        "    print(\"Analysis complete, generating plots...\")\n",
        "    plot_scaling_results(node_counts, avg_cuts, avg_wire_lengths, avg_critical_lengths)\n",
        "    \n",
        "    # Print some numerical results\n",
        "    print(\"\\nNumerical Results:\")\n",
        "    for i, nodes in enumerate(node_counts):\n",
        "        if avg_cuts[i] is not None:\n",
        "            print(f\"Nodes: {nodes:3d}, Cuts: {avg_cuts[i]:6.2f}, Wire Length: {avg_wire_lengths[i]:8.2f}, Critical Length: {avg_critical_lengths[i]:8.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
