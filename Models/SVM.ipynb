{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ§  SVM-Based VLSI Partitioning Model\n",
        "\n",
        "This notebook implements a Support Vector Machine (SVM)-based approach for partitioning VLSI netlists represented as graphs.\n",
        "\n",
        "### Model Logic:\n",
        "- Each node in the graph represents a circuit component with features:\n",
        "  - Power, Area, Average Edge Distance, Degree\n",
        "- Pseudo-labels for supervised learning are generated using **KMeans** clustering.\n",
        "- An **SVM classifier** is trained on the node features and labels.\n",
        "- After training, each node is assigned to a partition, and standard partitioning metrics are computed.\n",
        "\n",
        "### Goals:\n",
        "- Minimize inter-partition **cut edges**\n",
        "- Minimize total **wire length**\n",
        "- Balance **power and area** across partitions\n",
        "- Reduce **critical path delay**\n"
      ],
      "metadata": {
        "id": "uWFPufNodjE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import defaultdict\n",
        "import random, math\n"
      ],
      "metadata": {
        "id": "yNK48HXtdkzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_node_features(G):\n",
        "    features = []\n",
        "    node_ids = []\n",
        "    for node in G.nodes():\n",
        "        if node.startswith(\"IN_\") or node.startswith(\"OUT_\"):\n",
        "            continue\n",
        "        power = G.nodes[node].get(\"power\", 0)\n",
        "        area = G.nodes[node].get(\"area\", 0)\n",
        "        in_edges = G.in_edges(node)\n",
        "        out_edges = G.out_edges(node)\n",
        "        edge_distances = [G.edges[u, v].get(\"distance\", 1.0) for u, v in list(in_edges) + list(out_edges)]\n",
        "        avg_distance = np.mean(edge_distances) if edge_distances else 0.0\n",
        "        degree = G.in_degree(node) + G.out_degree(node)\n",
        "        features.append([power, area, avg_distance, degree])\n",
        "        node_ids.append(node)\n",
        "    return np.array(features), node_ids\n"
      ],
      "metadata": {
        "id": "qWAb-9ufdmfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_svm_model(G):\n",
        "    features, node_ids = extract_node_features(G)\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(features)\n",
        "\n",
        "    km = KMeans(n_clusters=2, n_init=10)\n",
        "    y_pseudo = km.fit_predict(X_scaled)\n",
        "\n",
        "    clf = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
        "    clf.fit(X_scaled, y_pseudo)\n",
        "    y_pred = clf.predict(X_scaled)\n",
        "\n",
        "    return {node_ids[i]: int(y_pred[i]) for i in range(len(node_ids))}\n"
      ],
      "metadata": {
        "id": "I0Flke-Fdn1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_partition_metrics(G, partition_map, input_nodes, output_nodes):\n",
        "    num_cuts = 0\n",
        "    total_wire_length = 0\n",
        "    G_weighted = nx.DiGraph()\n",
        "\n",
        "    for u, v in G.edges():\n",
        "        wire_length = G.edges[u, v].get(\"distance\", 1)\n",
        "        cluster_u = partition_map.get(u, -1)\n",
        "        cluster_v = partition_map.get(v, -1)\n",
        "\n",
        "        if cluster_u != -1 and cluster_v != -1:\n",
        "            if cluster_u != cluster_v:\n",
        "                wire_length *= 10\n",
        "                num_cuts += 1\n",
        "        total_wire_length += wire_length\n",
        "        G_weighted.add_edge(u, v, weight=wire_length)\n",
        "\n",
        "    while not nx.is_directed_acyclic_graph(G_weighted):\n",
        "        try:\n",
        "            cycle = next(nx.simple_cycles(G_weighted))\n",
        "            min_edge = min(((cycle[i], cycle[(i + 1) % len(cycle)]) for i in range(len(cycle))),\n",
        "                           key=lambda e: G_weighted.edges[e].get(\"weight\", 1))\n",
        "            G_weighted.remove_edge(*min_edge)\n",
        "        except StopIteration:\n",
        "            break\n",
        "\n",
        "    critical_delay = 0\n",
        "    for inp in input_nodes:\n",
        "        if inp in G_weighted.nodes:\n",
        "            for out in output_nodes:\n",
        "                if out in G_weighted.nodes:\n",
        "                    try:\n",
        "                        path = nx.dag_longest_path(G_weighted, weight=\"weight\")\n",
        "                        path_length = sum(G_weighted[u][v][\"weight\"] for u, v in zip(path, path[1:]))\n",
        "                        critical_delay = max(critical_delay, path_length)\n",
        "                    except nx.NetworkXNoPath:\n",
        "                        continue\n",
        "\n",
        "    return {\n",
        "        \"cut_edges\": num_cuts,\n",
        "        \"total_wire_length\": round(total_wire_length, 2),\n",
        "        \"critical_delay\": round(critical_delay, 2)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "Tp8U6GYJdpnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "from utils.graph_gen import generate_netlist\n",
        "\n",
        "G, inputs, outputs = generate_netlist(num_nodes=50, num_edges=100, seed=42)\n",
        "partition_map = train_svm_model(G)\n",
        "metrics = compute_partition_metrics(G, partition_map, inputs, outputs)\n",
        "\n",
        "print(metrics)\n"
      ],
      "metadata": {
        "id": "D6XK-NVmdsSa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}